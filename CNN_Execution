import numpy as np
import pandas as pd
import seaborn as sns
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Dense, Input
from tensorflow.keras.utils import to_categorical
import warnings
warnings.filterwarnings("ignore")

train = pd.read_csv("train.csv")
test = pd.read_csv("test.csv")

y = train["label"]
x = train.drop(labels = ["label"], axis = 1)
graph = sns.countplot(y)

X = x.to_numpy()
Y = y.to_numpy()
X = X.astype('float')/255.
x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 21)

x_train_noisy = x_train + np.random.rand(len(x_train), 784) * 0.9
x_test_noisy = x_test + np.random.rand(len(x_test), 784) * 0.9
x_train_noisy = np.clip(x_train_noisy, 0, 1)
x_test_noisy = np.clip(x_test_noisy, 0, 1)

def plot(x, p , labels = False):
    plt.figure(figsize = (20,2))
    for i in range(10):
        plt.subplot(1, 10, i+1)
        plt.imshow(x[i].reshape(28,28), cmap = 'binary')
        if labels:
            plt.xlabel(np.argmax(p[i]))
    plt.show()
    return
plot(x_train, "Normal")
plot(x_train_noisy, "Noisy")

model = Sequential([Dense(1024, activation = 'relu', input_shape = (784, )),
    Dense(512, activation = 'relu'),
    Dense(256, activation = 'relu'),
    Dense(10, activation = 'softmax')])
model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = 'accuracy')

model.summary()

model.fit(x_train, y_train, epochs = 20, batch_size = 512)

loss, acc = model.evaluate(x_test, y_test)

loss, acc = model.evaluate(x_test_noisy, y_test)

"""
We can see that the our model gives really good accuracy 
when the images are unnoised but gives extremely poor accuracy 
when images are noisy. 
In the next Increment, 
We'll try to implement improved model to denoise the images
"""

#REDNet Model

#DataSet Overview
We will be using the two publicly available tmp_ds for this case study. <br>
1. Smartphone Image Denoising tmp_ds (SIDD):- <br>
It consists of 160 image pairs of clean and its corresponding noisy image. 


!pip install opencv-python

!pip install patchify

#Importing relevant libraries
import os
import pandas as pd
import cv2
from google.colab.patches import cv2_imshow
import matplotlib.pyplot as plt
from patchify import patchify, unpatchify
import seaborn as sns
import random
import numpy as np
import math
from sklearn.model_selection import train_test_split
import pickle
import tensorflow as tf
from tensorflow.keras.callbacks import LearningRateScheduler,ReduceLROnPlateau
from tensorflow.keras import models, layers
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Conv2D, Conv2DTranspose, BatchNormalization, Activation, Flatten, Dense, Input, MaxPooling2D, Add, Reshape, concatenate, AveragePooling2D, Multiply, GlobalAveragePooling2D, UpSampling2D, MaxPool2D,Softmax
from tensorflow.keras.activations import softmax
from tensorflow.keras import initializers, regularizers
from tensorflow.keras.optimizers import Adam
from skimage.metrics import peak_signal_noise_ratio as psnr
from skimage.metrics import structural_similarity as ssim
%load_ext tensorboard

##Extracting Image paths for SIDD tmp_ds

dir = os.listdir('/content/drive/MyDrive/SIDD_Small_sRGB_Only_1/Data/')
folders=[]
#print(dir)
for folder in dir:
  folders.append(folder)

GT = []
Noisy = []
for folder in folders:
  #print(folder)
  files = os.listdir('/content/drive/MyDrive/SIDD_Small_sRGB_Only_1/Data/'+folder)
  if "GT" in files[0]:
    GT.append('/content/drive/MyDrive/SIDD_Small_sRGB_Only_1/Data/'+folder+'/'+files[0])
    Noisy.append('/content/drive/MyDrive/SIDD_Small_sRGB_Only_1/Data/'+folder+'/'+files[1])
  else:
    GT.append('/content/drive/MyDrive/SIDD_Small_sRGB_Only_1/Data/'+folder+'/'+files[1])
    Noisy.append('/content/drive/MyDrive/SIDD_Small_sRGB_Only_1/Data/'+folder+'/'+files[0])
print(GT)

#Reading data frame
df = pd.DataFrame()
df['GTI'] = GT
df['NI'] = Noisy
#Getting Ground Truth and Noisy Images from drive
df.head()

#Exploratory Data Analysis

size=[]
for i in range(len(df)):
  sample_gt = cv2.imread(df['GTI'].iloc[i]) #locating the data
  size.append(sample_gt.shape)#Getting size and appending to the Ground truth image info

X = df['NI'] 
y = df['GTI']

noisy_train_paths, noisy_test_paths, gt_train_paths, gt_test_paths = train_test_split(X, y, test_size=0.20, random_state=42)

!pip install tqdm

#Resizing and adding colors to the image and adding to list
from tqdm.notebook import tqdm
def image_getter(images_paths):
    i_list = []
    for i_path in tqdm(images_paths):
        i_tmp = cv2.imread(i_path)
        i_tmp = cv2.cvtColor(i_tmp, cv2.COLOR_BGR2RGB)
        i_tmp = cv2.resize(i_tmp, (256, 256))
        i_list.append(i_tmp)
    return np.array(i_list)

#Printing in array
nt_images = image_getter(noisy_train_paths)
n_test_img = image_getter(noisy_test_paths)

gt_img = image_getter(gt_train_paths)
g_test_img = image_getter(gt_test_paths)

print(nt_images.shape)
print(n_test_img.shape)

print(gt_img.shape)
print(g_test_img.shape)

f, ar = plt.subplots(1,2, figsize=(10,10))
#printing image
ar[0].imshow(nt_images[5])# Fivth one of Noisy Image
ar[0].set_title("Noisy image") 
ar[1].imshow(gt_img[5])
ar[1].title.set_text("Ground Truth image")

def ud_flip(tmp_img, tmp_lbl):
    tmp_img = tf.tmp_img.flip_up_down(tmp_img)
    tmp_lbl = tf.tmp_img.flip_up_down(tmp_lbl)
    return tmp_img, tmp_lbl

def lr_flip(tmp_img, tmp_lbl):
    tmp_img = tf.tmp_img.flip_left_right(tmp_img)
    tmp_lbl = tf.tmp_img.flip_left_right(tmp_lbl)
    return tmp_img, tmp_lbl

def _rotate(tmp_img, tmp_lbl):
    random_angle = tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32)
    tmp_img = tf.tmp_img.rot90(tmp_img, random_angle)
    tmp_lbl = tf.tmp_img.rot90(tmp_lbl, random_angle)
    return tmp_img, tmp_lbl

def _hue(tmp_img, tmp_lbl):
    r_v = random.uniform(-1,1)
    tmp_img = tf.tmp_img.adjust_hue(tmp_img, r_v)
    tmp_lbl = tf.tmp_img.adjust_hue(tmp_lbl, r_v)
    return tmp_img, tmp_lbl

def _brightness(tmp_img, tmp_lbl):
    r_v = random.uniform(-0.08,0.25)
    tmp_img = tf.tmp_img.adjust_brightness(tmp_img, r_v)
    tmp_lbl = tf.tmp_img.adjust_brightness(tmp_lbl, r_v)
    return tmp_img, tmp_lbl

def _saturation(tmp_img, tmp_lbl):
    r_v = random.uniform(1, 5)
    tmp_img = tf.tmp_img.adjust_saturation(tmp_img, r_v)
    tmp_lbl = tf.tmp_img.adjust_saturation(tmp_lbl, r_v)
    return tmp_img, tmp_lbl

def _contrast(tmp_img, tmp_lbl):
    r_v = random.uniform(1, 3)
    tmp_img = tf.tmp_img.adjust_contrast(tmp_img, r_v)
    tmp_lbl = tf.tmp_img.adjust_contrast(tmp_lbl, r_v)
    return tmp_img, tmp_lbl


# https://stackoverflow.com/q/53514495/7697658
def tf_data_generator(X, y, batch_size=32, augmentations=None):
    tmp_ds = tf.data.tmp_ds.from_tensor_slices((X, y)) # This is the main step for data generation
    tmp_ds = tmp_ds.shuffle(1000, reshuffle_each_iteration=True)

    if augmentations:
        for f in augmentations:
            if np.random.uniform(0,1)<0.5:
                tmp_ds = tmp_ds.map(f, num_parallel_calls=2)

    tmp_ds = tmp_ds.repeat()
    tmp_ds = tmp_ds.batch(batch_size=batch_size, drop_remainder=True)
    tmp_ds = tmp_ds.prefetch(tf.data.experimental.AUTOTUNE)
    return tmp_ds

BATCH_SIZE=4
augmentation_lst = [ud_flip, lr_flip, _rotate]
img_gt = tf_data_generator(X=nt_images, y=gt_img, batch_size=BATCH_SIZE, augmentations=augmentation_lst)
img_gtest = tf_data_generator(X=n_test_img, y=g_test_img, batch_size=BATCH_SIZE)

img_gt



# SANITY CHECK of the tmp_ds generator
for noisy, gt in img_gt.take(1):  # only take first element of tmp_ds
    numpy_images = noisy.numpy()
    numpy_tmp_lbls = gt.numpy()

f, ar = plt.subplots(1,2, figsize=(14,14))
ar[0].imshow(numpy_images[1])
ar[0].set_title("X-data noisy image")
ar[0].set_axis_off()

ar[1].imshow(numpy_tmp_lbls[1])
ar[1].set_title("y-data ground truth image")
ar[1].set_axis_off()



import tensorflow as tf
from tensorflow.keras import models, layers
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Conv2D, Conv2DTranspose, BatchNormalization, Activation, Flatten, Dense, Input, Add
from tensorflow.keras import initializers, regularizers
from tensorflow.keras.optimizers import Adam

#CNN Auto Encoder (Baseline model)

def create_model():
    tf.keras.backend.clear_session()

    input_0 = Input(shape=(256,256,3), name="input_layer")
    conv_layer_1 = Conv2D(filters=256, kernel_size=2, padding='same', name="conv_1")(input_0)
    conv_layer_2 = Conv2D(filters=256, kernel_size=2, padding='same', name="conv_2")(conv_layer_1)
    conv_layer_3 = Conv2D(filters=256, kernel_size=3, padding='same', name="conv_3")(conv_layer_2)
    conv_layer_4 = Conv2D(filters=256, kernel_size=3, padding='same', name="conv_4")(conv_layer_3)
    conv_layer_5 = Conv2D(filters=128, kernel_size=3, padding='same', name="conv_5")(conv_layer_4)

    deconv_layer_5 = Conv2DTranspose(filters=256, kernel_size=2, padding='same', name="deconv_5")(conv_layer_5)
    deconv_layer_5 = Add(name="add_1")([conv_layer_4, deconv_layer_5])
    deconv_layer_4 = Conv2DTranspose(filters=256, kernel_size=2, padding='same', name="deconv_4")(deconv_layer_5)
    deconv_layer_3 = Conv2DTranspose(filters=256, kernel_size=3, padding='same', name="deconv_3")(deconv_layer_4)
    deconv_layer_3 = Add(name="add_2")([conv_layer_2, deconv_layer_3])
    deconv_layer_2 = Conv2DTranspose(filters=128, kernel_size=3, padding='same', name="deconv_2")(deconv_layer_3)
    deconv_layer_1 = Conv2DTranspose(filters=3, kernel_size=3, padding='same', name="deconv_1")(deconv_layer_2)
    out = Add(name="add_3")([input_0, deconv_layer_1])

    model = Model(inputs=[input_0], outputs=[out])
    return model

model = create_model()
model.summary()

tf.keras.utils.plot_model(model=model, to_file='model_plot.png', show_shapes=True)

spet = len(nt_images) #steps per epoch train
spe_val = len(n_test_img) #steps_per_epoch_validation

best_models_path = "/content/drive/MyDrive/Colab Notebooks/Applied AI Assignments/Case Study 2 Image Denoising/Best Models/baseline model/"
callbacks_lst = [
    tf.keras.callbacks.ModelCheckpoint(filepath=best_models_path+"best_REDNet_blindnoise_256x256.h5", period=10, save_weights_only=False),
    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', min_lr=0.000009, min_delta=0.0001, factor=0.75, patience=3, verbose=1, mode='min'),
    tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, min_delta=0.0001, patience=10)
]

model.compile(loss=tf.keras.losses.MeanSquaredError(), optimizer=Adam(learning_rate=0.0001))
model.fit(img_gt, 
          validation_data=img_gtest,
                        steps_per_epoch=spet,
                        validation_steps=spe_val,
                        epochs=2, # epochs session
                        verbose=1,
                        callbacks=callbacks_lst)

best_models_path = "/content/drive/MyDrive/Colab Notebooks/Applied AI Assignments/Case Study 2 Image Denoising/Best Models/baseline model/"
model.save(best_models_path+"best_REDNet_blindnoise_256x256.h5")


# Inference

def inf_s_img(model, noisy_image): #single
    input_image = np.expand_dims(noisy_image, axis=0)
    predicted_image = model.predict(input_image)
    
    return predicted_image[0]

def inf_b_img(model, noisy_images): #batch
    predicted_image = model.predict(noisy_images, batch_size=4)
    return predicted_image

def visualize_predictions(model, X_test, y_test, n):
    random_numbers = random.choices(range(X_test.shape[0]), k=n)    # Get n random indices
    for i in random_numbers:
        noisy_image = X_test[i]
        gt_image = y_test[i]
        predicted_image = inf_s_img(model, X_test[i])
        predicted_image/=255

        f, ar = plt.subplots(1,3, figsize=(21,21))
        ar[0].imshow(noisy_image)
        ar[0].set_title("Noisy image")
        ar[0].set_axis_off()
        ar[1].imshow(gt_image)
        ar[1].set_title("Ground truth image")
        ar[1].set_axis_off()
        ar[2].imshow(predicted_image)
        ar[2].set_title("Predicted image")
        ar[2].set_axis_off()

best_models_path = "/content/drive/MyDrive/Colab Notebooks/Applied AI Assignments/Case Study 2 Image Denoising/Best Models/baseline model/"
model = tf.keras.models.load_model(best_models_path+'best_REDNet_blindnoise_256x256.h5')

visualize_predictions(model, n_test_img, g_test_img, 10)

# Test image prediction
banana = "NIND_banana_ISOH3.png"
kibbles = "NIND_kibbles_ISOH3.png"
library = "NIND_BruegelLibraryS1_NZ.png"
parrots = "kodim23-noise-std51.png"
eye = "eye_closeup_smaller_DIM25_noise_stddev_51.png"

I_path = "/content/noi.jpg"

img = cv2.imread(I_path)
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
img = cv2.resize(img, (256, 256))

predicted_image = inf_s_img(model, img)
predicted_image/=255

f, ar = plt.subplots(1,2, figsize=(14,14))
ar[0].imshow(img)
ar[0].title.set_text("Noisy image")
ar[0].set_axis_off()

ar[1].imshow(predicted_image)
ar[1].title.set_text("Predicted image")
ar[1].set_axis_off()

from skimage.metrics import peak_signal_noise_ratio

predicted_images = inf_b_img(model, n_test_img)
psnr_original_mean = 0
psnr_prediction_mean = 0

for gt_img, noisy_img, predicted_img in zip(g_test_img, n_test_img, predicted_images):
    psnr_original_mean += peak_signal_noise_ratio(gt_img, noisy_img)
    psnr_prediction_mean += peak_signal_noise_ratio(gt_img, predicted_img)

psnr_original_mean/=g_test_img.shape[0]
psnr_prediction_mean/=g_test_img.shape[0]
print("Original average gt-noisy PSNR ->", psnr_original_mean)
print("Predicted average gt-predicted PSNR ->", psnr_prediction_mean)

from skimage.metrics import structural_similarity as ssim

predicted_images = inf_b_img(model, n_test_img)
ssim_original_mean = 0
ssim_prediction_mean = 0

for gt_img, noisy_img, predicted_img in zip(g_test_img, n_test_img, predicted_images):
    ssim_original_mean += ssim(gt_img, noisy_img, multichannel=True, data_range=noisy_img.max() - noisy_img.min())
    ssim_prediction_mean += ssim(gt_img, predicted_img, multichannel=True, data_range=predicted_img.max() - predicted_img.min())

ssim_original_mean/=g_test_img.shape[0]
ssim_prediction_mean/=g_test_img.shape[0]
print("Original average gt-noisy SSIM ->", ssim_original_mean)
print("Predicted average gt-predicted SSIM ->", ssim_prediction_mean)

from prettytable import PrettyTable

pt = PrettyTable()
print("Note: Improvements shown are over original pairs")
pt.field_names = ["Model", "PSNR", "SSIM", "PSNR Improvement", "SSIM improvement"]

pt.add_row(["Original X-y pairs (No Model)","26.3779","0.6000", "-", "-"])
pt.add_row(["REDNet (Baseline)","30.5713","0.7932", "4.1934","0.1932"])
pt.add_row(["MWCNN (using Wavelets)","32.5220","0.8397","6.1441","0.2397"])
pt.add_row(["PRIDNet (using Attention)","33.3105","0.8534","6.9326","0.2534"])

print(pt)
