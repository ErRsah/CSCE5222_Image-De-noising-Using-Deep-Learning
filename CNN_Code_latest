#Importing relevant libraries
import os
import pandas as pd
import cv2
from google.colab.patches import cv2_imshow
import matplotlib.pyplot as plt
from patchify import patchify, unpatchify
import seaborn as sns
import random
import numpy as np
import math
from sklearn.model_selection import train_test_split
import pickle
import tensorflow as tf
from tensorflow.keras.callbacks import LearningRateScheduler,ReduceLROnPlateau
from tensorflow.keras import models, layers
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Conv2D, Conv2DTranspose, BatchNormalization, Activation, Flatten, Dense, Input, MaxPooling2D, Add, Reshape, concatenate, AveragePooling2D, Multiply, GlobalAveragePooling2D, UpSampling2D, MaxPool2D,Softmax
from tensorflow.keras.activations import softmax
from tensorflow.keras import initializers, regularizers
from tensorflow.keras.optimizers import Adam
from skimage.metrics import peak_signal_noise_ratio as psnr
from skimage.metrics import structural_similarity as ssim
%load_ext tensorboard

##Extracting Image paths for SIDD tmp_ds

dir = os.listdir('/content/drive/MyDrive/SIDD_Small_sRGB_Only_1/Data/')
folders=[]
#print(dir)
for folder in dir:
  folders.append(folder)

GT = []
Noisy = []
for folder in folders:
  #print(folder)
  files = os.listdir('/content/drive/MyDrive/SIDD_Small_sRGB_Only_1/Data/'+folder)
  if "GT" in files[0]:
    GT.append('/content/drive/MyDrive/SIDD_Small_sRGB_Only_1/Data/'+folder+'/'+files[0])
    Noisy.append('/content/drive/MyDrive/SIDD_Small_sRGB_Only_1/Data/'+folder+'/'+files[1])
  else:
    GT.append('/content/drive/MyDrive/SIDD_Small_sRGB_Only_1/Data/'+folder+'/'+files[1])
    Noisy.append('/content/drive/MyDrive/SIDD_Small_sRGB_Only_1/Data/'+folder+'/'+files[0])
print(GT)

#Reading data frame
df = pd.DataFrame()
df['GTI'] = GT
df['NI'] = Noisy
#Getting Ground Truth and Noisy Images from drive
df.head()

#Exploratory Data Analysis

size=[]
for i in range(len(df)):
  sample_gt = cv2.imread(df['GTI'].iloc[i]) #locating the data
  size.append(sample_gt.shape)#Getting size and appending to the Ground truth image info

X = df['NI'] 
y = df['GTI']

noisy_train_paths, noisy_test_paths, gt_train_paths, gt_test_paths = train_test_split(X, y, test_size=0.20, random_state=42)

!pip install tqdm

#Resizing and adding colors to the image and adding to list
from tqdm.notebook import tqdm
def image_getter(images_paths):
    i_list = []
    for i_path in tqdm(images_paths):
        i_tmp = cv2.imread(i_path)
        i_tmp = cv2.cvtColor(i_tmp, cv2.COLOR_BGR2RGB)
        i_tmp = cv2.resize(i_tmp, (256, 256))
        i_list.append(i_tmp)
    return np.array(i_list)

#Printing in array
nt_images = image_getter(noisy_train_paths)
n_test_img = image_getter(noisy_test_paths)

gt_img = image_getter(gt_train_paths)
g_test_img = image_getter(gt_test_paths)

print(nt_images.shape)
print(n_test_img.shape)

print(gt_img.shape)
print(g_test_img.shape)

f, ar = plt.subplots(1,2, figsize=(10,10))
#printing image
ar[0].imshow(nt_images[5])# Fivth one of Noisy Image
ar[0].set_title("Noisy image") 
ar[1].imshow(gt_img[5])
ar[1].title.set_text("Ground Truth image")

def ud_flip(tmp_img, tmp_lbl):
    tmp_img = tf.tmp_img.flip_up_down(tmp_img)
    tmp_lbl = tf.tmp_img.flip_up_down(tmp_lbl)
    return tmp_img, tmp_lbl

def lr_flip(tmp_img, tmp_lbl):
    tmp_img = tf.tmp_img.flip_left_right(tmp_img)
    tmp_lbl = tf.tmp_img.flip_left_right(tmp_lbl)
    return tmp_img, tmp_lbl

def _rotate(tmp_img, tmp_lbl):
    random_angle = tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32)
    tmp_img = tf.tmp_img.rot90(tmp_img, random_angle)
    tmp_lbl = tf.tmp_img.rot90(tmp_lbl, random_angle)
    return tmp_img, tmp_lbl

def _hue(tmp_img, tmp_lbl):
    r_v = random.uniform(-1,1)
    tmp_img = tf.tmp_img.adjust_hue(tmp_img, r_v)
    tmp_lbl = tf.tmp_img.adjust_hue(tmp_lbl, r_v)
    return tmp_img, tmp_lbl

def _brightness(tmp_img, tmp_lbl):
    r_v = random.uniform(-0.08,0.25)
    tmp_img = tf.tmp_img.adjust_brightness(tmp_img, r_v)
    tmp_lbl = tf.tmp_img.adjust_brightness(tmp_lbl, r_v)
    return tmp_img, tmp_lbl

def _saturation(tmp_img, tmp_lbl):
    r_v = random.uniform(1, 5)
    tmp_img = tf.tmp_img.adjust_saturation(tmp_img, r_v)
    tmp_lbl = tf.tmp_img.adjust_saturation(tmp_lbl, r_v)
    return tmp_img, tmp_lbl

def _contrast(tmp_img, tmp_lbl):
    r_v = random.uniform(1, 3)
    tmp_img = tf.tmp_img.adjust_contrast(tmp_img, r_v)
    tmp_lbl = tf.tmp_img.adjust_contrast(tmp_lbl, r_v)
    return tmp_img, tmp_lbl


# https://stackoverflow.com/q/53514495/7697658
def tf_data_generator(X, y, batch_size=32, augmentations=None):
    tmp_ds = tf.data.tmp_ds.from_tensor_slices((X, y)) # This is the main step for data generation
    tmp_ds = tmp_ds.shuffle(1000, reshuffle_each_iteration=True)

    if augmentations:
        for f in augmentations:
            if np.random.uniform(0,1)<0.5:
                tmp_ds = tmp_ds.map(f, num_parallel_calls=2)

    tmp_ds = tmp_ds.repeat()
    tmp_ds = tmp_ds.batch(batch_size=batch_size, drop_remainder=True)
    tmp_ds = tmp_ds.prefetch(tf.data.experimental.AUTOTUNE)
    return tmp_ds

BATCH_SIZE=4
augmentation_lst = [ud_flip, lr_flip, _rotate]
img_gt = tf_data_generator(X=nt_images, y=gt_img, batch_size=BATCH_SIZE, augmentations=augmentation_lst)
img_gtest = tf_data_generator(X=n_test_img, y=g_test_img, batch_size=BATCH_SIZE)

img_gt



# SANITY CHECK of the tmp_ds generator
for noisy, gt in img_gt.take(1):  # only take first element of tmp_ds
    numpy_images = noisy.numpy()
    numpy_tmp_lbls = gt.numpy()

f, ar = plt.subplots(1,2, figsize=(14,14))
ar[0].imshow(numpy_images[1])
ar[0].set_title("X-data noisy image")
ar[0].set_axis_off()

ar[1].imshow(numpy_tmp_lbls[1])
ar[1].set_title("y-data ground truth image")
ar[1].set_axis_off()



import tensorflow as tf
from tensorflow.keras import models, layers
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Conv2D, Conv2DTranspose, BatchNormalization, Activation, Flatten, Dense, Input, Add
from tensorflow.keras import initializers, regularizers
from tensorflow.keras.optimizers import Adam

#CNN Auto Encoder (Baseline model)

def create_model():
    tf.keras.backend.clear_session()

    input_0 = Input(shape=(256,256,3), name="input_layer")
    conv_layer_1 = Conv2D(filters=256, kernel_size=2, padding='same', name="conv_1")(input_0)
    conv_layer_2 = Conv2D(filters=256, kernel_size=2, padding='same', name="conv_2")(conv_layer_1)
    conv_layer_3 = Conv2D(filters=256, kernel_size=3, padding='same', name="conv_3")(conv_layer_2)
    conv_layer_4 = Conv2D(filters=256, kernel_size=3, padding='same', name="conv_4")(conv_layer_3)
    conv_layer_5 = Conv2D(filters=128, kernel_size=3, padding='same', name="conv_5")(conv_layer_4)

    deconv_layer_5 = Conv2DTranspose(filters=256, kernel_size=2, padding='same', name="deconv_5")(conv_layer_5)
    deconv_layer_5 = Add(name="add_1")([conv_layer_4, deconv_layer_5])
    deconv_layer_4 = Conv2DTranspose(filters=256, kernel_size=2, padding='same', name="deconv_4")(deconv_layer_5)
    deconv_layer_3 = Conv2DTranspose(filters=256, kernel_size=3, padding='same', name="deconv_3")(deconv_layer_4)
    deconv_layer_3 = Add(name="add_2")([conv_layer_2, deconv_layer_3])
    deconv_layer_2 = Conv2DTranspose(filters=128, kernel_size=3, padding='same', name="deconv_2")(deconv_layer_3)
    deconv_layer_1 = Conv2DTranspose(filters=3, kernel_size=3, padding='same', name="deconv_1")(deconv_layer_2)
    out = Add(name="add_3")([input_0, deconv_layer_1])

    model = Model(inputs=[input_0], outputs=[out])
    return model

model = create_model()
model.summary()

tf.keras.utils.plot_model(model=model, to_file='model_plot.png', show_shapes=True)

spet = len(nt_images) #steps per epoch train
spe_val = len(n_test_img) #steps_per_epoch_validation

best_models_path = "/content/drive/MyDrive/Colab Notebooks/Applied AI Assignments/Case Study 2 Image Denoising/Best Models/baseline model/"
callbacks_lst = [
    tf.keras.callbacks.ModelCheckpoint(filepath=best_models_path+"best_REDNet_blindnoise_256x256.h5", period=10, save_weights_only=False),
    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', min_lr=0.000009, min_delta=0.0001, factor=0.75, patience=3, verbose=1, mode='min'),
    tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, min_delta=0.0001, patience=10)
]

model.compile(loss=tf.keras.losses.MeanSquaredError(), optimizer=Adam(learning_rate=0.0001))
model.fit(img_gt, 
          validation_data=img_gtest,
                        steps_per_epoch=spet,
                        validation_steps=spe_val,
                        epochs=2, # epochs session
                        verbose=1,
                        callbacks=callbacks_lst)

best_models_path = "/content/drive/MyDrive/Colab Notebooks/Applied AI Assignments/Case Study 2 Image Denoising/Best Models/baseline model/"
model.save(best_models_path+"best_REDNet_blindnoise_256x256.h5")
